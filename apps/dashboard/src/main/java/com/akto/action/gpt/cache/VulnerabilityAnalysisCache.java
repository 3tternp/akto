package com.akto.action.gpt.cache;

import com.akto.dao.context.Context;
import com.mongodb.BasicDBObject;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Iterator;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * In-memory cache for vulnerability analysis results to avoid repeated LLM calls
 * for the same test data. Uses ConcurrentHashMap with TTL and size limits.
 */
public class VulnerabilityAnalysisCache {
    
    private static final Logger logger = LoggerFactory.getLogger(VulnerabilityAnalysisCache.class);
    
    // Cache configuration
    private static final int MAX_CACHE_SIZE = 1000;
    private static final int CACHE_TTL_SECONDS = 48 * 60 * 60; // 48 hours in seconds
    
    // Singleton instance
    private static volatile VulnerabilityAnalysisCache instance;
    
    private final Map<String, CacheEntry> cache;
    
    private static class CacheEntry {
        private final BasicDBObject result;
        private final int timestamp;
        
        public CacheEntry(BasicDBObject result) {
            this.result = result;
            this.timestamp = Context.now();
        }
        
        public BasicDBObject getResult() {
            return result;
        }
        
        public boolean isExpired() {
            return (Context.now() - timestamp) > CACHE_TTL_SECONDS;
        }
    }
    
    private VulnerabilityAnalysisCache() {
        this.cache = new ConcurrentHashMap<>();
        
        logger.info("VulnerabilityAnalysisCache initialized with max size: {} and TTL: {} seconds", 
                   MAX_CACHE_SIZE, CACHE_TTL_SECONDS);
    }
    
    public static VulnerabilityAnalysisCache getInstance() {
        if (instance == null) {
            synchronized (VulnerabilityAnalysisCache.class) {
                if (instance == null) {
                    instance = new VulnerabilityAnalysisCache();
                }
            }
        }
        return instance;
    }
    
    /**
     * Generate a unique cache key for vulnerability analysis
     * Simple format: "vuln_analysis:{testResultId}"
     * Returns null if testResultId is not valid (indicating caching should be skipped)
     */
    public String generateCacheKey(String testResultId, BasicDBObject testData) {
        // Only generate cache key if we have a valid test result ID
        if (testResultId == null || testResultId.isEmpty()) {
            return null;
        }
        
        // Simple key: just the test result ID with prefix
        return "vuln_analysis:" + testResultId;
    }
    
    
    /**
     * Get cached vulnerability analysis result
     */
    public BasicDBObject get(String key) {
        CacheEntry entry = cache.get(key);
        if (entry != null) {
            if (entry.isExpired()) {
                cache.remove(key);
                return null;
            } else {
                return entry.getResult();
            }
        }
        return null;
    }
    
    /**
     * Store vulnerability analysis result in cache
     */
    public void put(String key, BasicDBObject result) {
        // Clean up expired entries and enforce size limit
        cleanupExpiredEntries();
        enforceSizeLimit();
        
        cache.put(key, new CacheEntry(result));
    }
    
    /**
     * Clean up expired entries from cache
     */
    private void cleanupExpiredEntries() {
        Iterator<Map.Entry<String, CacheEntry>> iterator = cache.entrySet().iterator();
        while (iterator.hasNext()) {
            Map.Entry<String, CacheEntry> entry = iterator.next();
            if (entry.getValue().isExpired()) {
                iterator.remove();
            }
        }
    }
    
    /**
     * Enforce cache size limit by removing oldest entries
     */
    private void enforceSizeLimit() {
        if (cache.size() >= MAX_CACHE_SIZE) {
            // Remove oldest entries (simple approach - remove first entries)
            Iterator<Map.Entry<String, CacheEntry>> iterator = cache.entrySet().iterator();
            int toRemove = cache.size() - MAX_CACHE_SIZE + 1; // Remove one extra to make room
            int removed = 0;
            while (iterator.hasNext() && removed < toRemove) {
                iterator.next();
                iterator.remove();
                removed++;
            }
        }
    }
    
    /**
     * Get cache statistics for monitoring
     */
    public String getCacheStats() {
        cleanupExpiredEntries();
        return String.format("Cache stats - Size: %d, Max Size: %d, TTL: %d seconds",
                cache.size(), MAX_CACHE_SIZE, CACHE_TTL_SECONDS);
    }
    
    /**
     * Clear all cached entries (useful for testing or manual cache invalidation)
     */
    public void clear() {
        cache.clear();
        logger.info("VulnerabilityAnalysisCache cleared");
    }
    
    /**
     * Remove specific entry from cache
     */
    public void remove(String key) {
        cache.remove(key);
    }
}
